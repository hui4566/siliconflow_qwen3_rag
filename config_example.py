# é…ç½®ç¤ºä¾‹æ–‡ä»¶
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º config.py å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹è®¾ç½®

# ç¡…åŸºæµåŠ¨ API é…ç½®
SILICONFLOW_CONFIG = {
    "api_base": "https://api.siliconflow.cn/v1",
    "timeout": 60,  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    "max_retries": 3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
}

# æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    "generative_models": [
        "Qwen/Qwen3-235B-A22B",
        "deepseek-ai/DeepSeek-V3",
        "Qwen/Qwen2.5-72B-Instruct",
        "meta-llama/Meta-Llama-3.1-405B-Instruct"
    ],
    "embedding_models": [
        "Qwen/Qwen3-Embedding-8B",
        "BAAI/bge-large-zh-v1.5",
        "text-embedding-3-large"
    ],
    "default_generative": "Qwen/Qwen3-235B-A22B",
    "default_embedding": "Qwen/Qwen3-Embedding-8B"
}

# LLM å‚æ•°é…ç½®
LLM_PARAMS = {
    "temperature": 0.7,
    "max_tokens": 2048,
    "top_p": 0.9,
    "frequency_penalty": 0.0,
    "presence_penalty": 0.0
}

# RAG é…ç½®
RAG_CONFIG = {
    "similarity_top_k": 5,  # æ£€ç´¢çš„ç›¸å…³æ–‡æ¡£æ•°é‡
    "chunk_size": 1024,     # æ–‡æ¡£åˆ†å—å¤§å°
    "chunk_overlap": 200,   # åˆ†å—é‡å å¤§å°
    "response_mode": "compact"  # å“åº”æ¨¡å¼
}

# Streamlit ç•Œé¢é…ç½®
UI_CONFIG = {
    "page_title": "ç¡…åŸºæµåŠ¨ Qwen3 RAG èŠå¤©",
    "page_icon": "ğŸ¤–",
    "layout": "wide",
    "sidebar_width": 300,
    "max_file_size": 200,  # MB
    "supported_formats": ["pdf"]
}

# æ—¥å¿—é…ç½®
LOGGING_CONFIG = {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "file": "app.log"
}
